{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Solution_Tensorflow_Dataloader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDF0jjCqiiAF"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osipov/edu/blob/master/tf0/Solution_Tensorflow_Dataloader.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5yuXDh4W5zq"
      },
      "source": [
        "## **TODO:** Set the value of `URL` below to the URL from your learning materials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T11:15:06.196776Z",
          "start_time": "2021-02-23T11:15:06.101945Z"
        },
        "id": "gk1soslgW8Xv"
      },
      "source": [
        "URL = None\n",
        "import os\n",
        "assert URL and (type(URL) is str), \"Be sure to initialize URL using the value from your learning materials\"\n",
        "os.environ['URL'] = URL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T11:15:06.199108Z",
          "start_time": "2021-02-23T11:15:06.109Z"
        },
        "id": "1A_X7a8CW-UK"
      },
      "source": [
        "%%bash\n",
        "wget -q $URL -O ./data.zip\n",
        "mkdir -p data\n",
        "find *.zip | xargs unzip -o -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-mOZ6oR8q6K"
      },
      "source": [
        "## Use TensorFlow `Dataset` and `from_tensor_slices` with a structured dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:01:19.415400Z",
          "start_time": "2021-02-23T12:01:17.583971Z"
        },
        "id": "3oKWxWlmun66"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tfd\n",
        "\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "# building blocks of our network\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p8W9ZSL9I9w"
      },
      "source": [
        "Read the files that match `part-*.csv` from the `data` subdirectory into a Pandas data frame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:01:33.236073Z",
          "start_time": "2021-02-23T12:01:23.794741Z"
        },
        "id": "I3fr0_i_YEFf"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "df = pd.concat(\n",
        "    pd.read_csv(file) for file in Path('data/').glob('part-*.csv')\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RULBK-A9X7D"
      },
      "source": [
        "## Explore the `df` data frame, including the column names, the first few rows of the dataset, and the data frame's memory usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T11:16:12.780900Z",
          "start_time": "2021-02-23T11:16:12.760753Z"
        },
        "id": "3vDc_ZNI9ilK"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:01:47.615284Z",
          "start_time": "2021-02-23T12:01:47.045633Z"
        },
        "id": "uY4lLvmL9kne"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:01:51.425471Z",
          "start_time": "2021-02-23T12:01:50.154182Z"
        },
        "id": "xkZWfcKriRso"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-kVFhml9p0x"
      },
      "source": [
        "## Drop the `origindatetime_tr` column from the data frame. \n",
        "\n",
        "For now you are going to predict the taxi fare just based on the lat/lon coordinates of the pickup and the drop off locations. Remove the `origindatetime_tr` column from the data frame in your working dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:01:54.105883Z",
          "start_time": "2021-02-23T12:01:53.944896Z"
        },
        "id": "jhZpJTVZaas_"
      },
      "source": [
        "working_df = df.drop('origindatetime_tr', axis = 1)\n",
        "working_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aA0NkUA_x1M"
      },
      "source": [
        "## Sample 10% of your working dataset into a test dataset data frame\n",
        "\n",
        "* **hint:** use the Pandas `sample` function with the dataframe. Specify a value for the `random_state` to achieve reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:01:56.584609Z",
          "start_time": "2021-02-23T12:01:56.143540Z"
        },
        "id": "nsh_vPXiZr9J"
      },
      "source": [
        "test_df = working_df.sample(frac = 0.10, random_state = 42)\n",
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5FschugACN-"
      },
      "source": [
        "## Drop the rows that exist in your test dataset from the working dataset to produce a training dataset.\n",
        "\n",
        "* **hint** DataFrame's `drop` function can use index values from a data frame to drop specific rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:03.829409Z",
          "start_time": "2021-02-23T12:01:58.765276Z"
        },
        "id": "CT-b2IlIZ9FP"
      },
      "source": [
        "train_df = working_df.drop(index = test_df.index)\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R0P1sBeAX15"
      },
      "source": [
        "## Define 2 Python lists: 1st for the feature column names; 2nd for the target column name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:07.834557Z",
          "start_time": "2021-02-23T12:02:07.831903Z"
        },
        "id": "s62k_A-Ga-0x"
      },
      "source": [
        "FEATURES = ['origin_block_latitude','origin_block_longitude','destination_block_latitude','destination_block_longitude']\n",
        "TARGET = ['fareamount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttQDA-m8AgQx"
      },
      "source": [
        "## Create `X` and `y` tensors with the values of your feature and target columns in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:10.878033Z",
          "start_time": "2021-02-23T12:02:09.916890Z"
        },
        "id": "hX2dlZgpbA6I"
      },
      "source": [
        "X_train = tf.constant(train_df[FEATURES].values)\n",
        "y_train = tf.constant(train_df[TARGET].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQm_SJFDAqqn"
      },
      "source": [
        "## Create a `TensorSliceDataset` instance with the `y` and `X` tensors (in that order)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:19.398508Z",
          "start_time": "2021-02-23T12:02:19.393660Z"
        },
        "id": "ffqTuheNbLpj"
      },
      "source": [
        "train_ds = Dataset.from_tensor_slices((X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElrnaKEtAyEg"
      },
      "source": [
        "## Create a `BatchDataset` instance specifying a custom batch size\n",
        "\n",
        "A batch size of `2 ** 18 = 262,144` should work well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:20.746712Z",
          "start_time": "2021-02-23T12:02:20.741228Z"
        },
        "id": "-1YyY4tgbalF"
      },
      "source": [
        "BATCH_SIZE = 2 ** 18\n",
        "train_ds = train_ds.batch(batch_size=BATCH_SIZE)\n",
        "len(train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA-3bXKABCW_"
      },
      "source": [
        "## Create a model using `keras.Dense`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:24.863459Z",
          "start_time": "2021-02-23T12:02:24.843786Z"
        },
        "id": "6vYGtKDeajQk"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(\n",
        "    Dense(units=1, input_shape=[len(FEATURES)], activation='linear')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:27.257559Z",
          "start_time": "2021-02-23T12:02:27.252057Z"
        },
        "id": "8zC1H4EviRss"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UvsR9gBGXj"
      },
      "source": [
        "## Create an instance of the `Adam` optimizer for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:31.233110Z",
          "start_time": "2021-02-23T12:02:31.230098Z"
        },
        "id": "vPFF7EtFBKes"
      },
      "source": [
        "LEARNING_RATE = 0.003\n",
        "optimizer = Adam( learning_rate = LEARNING_RATE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz7LW-TnBNJu"
      },
      "source": [
        "## Declare your `loss` function using `keras.losses.MeanSquaredError`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:34.169648Z",
          "start_time": "2021-02-23T12:02:34.166771Z"
        },
        "id": "0T3aWJEZdiVH"
      },
      "source": [
        "loss_fn = tf.keras.losses.MeanSquaredError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfu2ejeoBfpQ"
      },
      "source": [
        "## Iterate over the batches returned by your `BatchDataset` instance\n",
        "\n",
        "For every step of gradient descent, print out the MSE, RMSE, and the batch index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:02:51.729396Z",
          "start_time": "2021-02-23T12:02:43.487049Z"
        },
        "id": "bVjF8VYwbATZ"
      },
      "source": [
        "for step, (X_train_batch, y_train_batch) in enumerate(train_ds):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # forward pass\n",
        "        y_pred = model(X_train_batch, training=True)\n",
        "        \n",
        "        # compute loss\n",
        "        loss = loss_fn(y_train_batch, y_pred)\n",
        "        \n",
        "    # backpropagation\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    \n",
        "    # monitor performance\n",
        "    loss_val, rmse = float(loss), float(tf.math.sqrt(loss))\n",
        "    print(f'batch {step+1:2d}:  loss={loss_val:7.2f}, RMSE={rmse:7.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVl44Jq5CApl"
      },
      "source": [
        "## Implement 10 epochs of gradient descent training\n",
        "\n",
        "For every step of gradient descent, printout the MSE, RMSE, epoch index, and batch index.\n",
        "\n",
        "* **hint:** you can call `enumerate(BatchDataset)` repeatedly in a `for` loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-23T12:04:41.532642Z",
          "start_time": "2021-02-23T12:03:21.287590Z"
        },
        "id": "hHtI3TB8ewaF"
      },
      "source": [
        "EPOCHS=10\n",
        "for epoch in range(EPOCHS):\n",
        "    for step, (X_train_batch, y_train_batch) in enumerate(train_ds):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # forward pass\n",
        "            y_pred = model(X_train_batch, training=True)\n",
        "\n",
        "            # compute loss\n",
        "            loss = loss_fn(y_train_batch, y_pred)\n",
        "\n",
        "        # back propogation\n",
        "        grads = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # monitor performance\n",
        "        loss_val, rmse = float(loss), float(tf.math.sqrt(loss))\n",
        "        if (step==0):\n",
        "            print(f'epoch {epoch+1:2d} ...')\n",
        "        print(f'  -- batch {step+1:2d}:  loss={loss_val:7.2f}, RMSE={rmse:7.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlrLCc3SCmuk"
      },
      "source": [
        "Copyright 2021 CounterFactual.AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}